### 머신러닝 파이프라인을 통해 얻는 이점
- 생산성 향상
- 예측 가능한 품질
- 장애 대응 능력 향상
  - 머신러닝 프로덕트는 다른 프로덕트보다 장애로 인지하기 더 힘듬
- poc 레벨에서 production 레벨로 올리기위해 pipeline 은 필수

### 머신러닝 파이프라인의 이해
- 대부분의 회사에서 머신러닝 모델 배포는 쉬워졌음 (MLOPS level 0)
- 머신러닝 모델을 운영하기가 힘들다
  - ML 시스템 개발 및 배포는 비교적 쉽고 빠름
  - 유지 관리 비용 매우 큼

- 일반적으로 기술부채를 없애는 기법 (유지 보수성 향상)
  - 리팩토링
  - 종속성 제거
  - 단위 테스트 (quality 유지 지속적 integration)
  - api 강화
  - 미사용 코드 삭제
  - 문서화

- 하지만 ML 시스템에서는  기존에 알려진 코드 수준의 기술 부채 제거 방식으로는 문제를 해결하기 어려움
  - 추상화의 경계가 무너짐
  - unit test 어려움
  - 부분적 계산 어려움

- 이런것들을 ML 프로덕트의 고질적인 문제를 푸는 것이 머신러닝 파이프라인의 핵심적인 기능

### 머신러닝 문제의 특징

- 쉬운 머신러닝 문제
  - 데이터의 변화가 천천히 일어날때
    - 분기, 월 단위
  - 모델 재학습이 다음에 의해 일어날때
    - 더 많은 데이터로 모델 성능 개선
    - 소프트웨어 혹은 시스템의 변화
  - 라벨링
    - 수집한 데이터
    - 크라우드 소싱

- 어려운 머신러닝 문제
  - 데이터의 변화가 빠르게 일어남
    - 주단위
  - 모델 재학습이 다음에 의해 일어날때
    - 모델 성능 저하
    - 더 많은 데이터로 모델 성능 개선
    - 소프트웨어 혹은 시스템의 변화
  - 라벨링
    - 직접적 피드백



### 좋은 머신러닝 프로그래밍
- 고정된 데이터 세트 -> 진화하는 데이터셋과 metric
- 통합 불가능한 아티팩트 -> 재사용 가능한 모델들
- 문제 정의 없음 -> 문제정의  찾기 쉬운 아티팩트
- 검증되지 않은 데이터셋, 모델 -> 예상치, 데이터 검증, 모델 검증
  - silent failure
  - 나이 값에 음수가 들어간다던지..
- 코드 한번으로 벤치마킹 되지 않거나 해킹 최적화 -> 모델의 성능과 품질을 벤치마크
- 편향된 데이터셋, 아티팩트 -> [데이터, 모델] *[ 설명가능성, 공정성]
- 시각화 요약 이해
- 아티팩트의 형상관리


### 머신러닝 프로덕트를 만든다고 했을때 데이터 엔지니어링이 상당히 많이 필요함

### 팀의 구성

- 팀의 구성이 상이함

- SW 프로젝트는 SW Engineer 로 구성
- ML 프로젝트는
  - Research Scientist (ph.d)
  - Research Engineer
  - Software Engineer
- 로 구성된다
  - Research Scientist 들이 software 역량을 갖추고 있는 케이스가 매우드뭄
  - 모델을 가져다 줬지만 software 화 하기 힘든 경우들, 혹은 software 용어를 전혀 몰라서 커뮤니케이션 에러가 있을 수 있음

### 개발 프로세스

- 일반 개발과 ML 개발의 프로세스가 상이함
  - ML은 본질적으로 실험
  - 다른 feature, 알고리즘, 모델링, 기술, 파라미터, 구성을 시도 가능한 빨리 문제점에 가장 적합한 것 찾음
  - 무엇이 효과가 있었는지 무엇이 그렇지 않은지를 추적하고
  - 코드 재사용을 극대화 하면서 재현성을 유지

### 테스팅 방법

- ML 시스템 테스트는 SW 시스템 테스트보다 더 복잡하다

### 배포 방법
- ML 시스템에서, 오프라인에서 훈련된 ML 모델을 구축하는 것 만큼 간단하지 않다
  - scaling out 도 해야함
- 기존 SW CI/CD 는 단일 trigger point
  - 코드 push merge
- 하지만 ML 은 trigger point 가 여러개일 수 있다
  - 학습이 다 되었다고 배포를 시키지 않음
    - 머신러닝 모델 코드 반영 -> 성능 검증 -> 배포
    - 머신러닝 모델 성능 저하 -> 재학습 -> 배포
    - daily 로 학습 -> 배포
    - online realtime 학습 -> 배포
  - 머신러닝 모델이 정상적으로 잘 동작하는지 확인이 명확하지 않음

### 프로덕션
- ML 모델은 코딩 뿐만 아니라
- 지속적으로 발전하는 데이터 프로파일 때문에 성능 저하 될 수 있음
- 데이터의 통계치 추적하고 모델의 온라인 성능을 모니터링해 예상치를 벗어날 때 알림을 보내거나 rollback 해야됨
  - 이상상황 인지 계획, 기준 같은것을 셋업 하고 진행해야한다

### 트리거

- 머신러닝은 다음과 같은 상황에서 학습과 모델을 배포
  - 요청 시: 파이프라인의 임시 수동 실행
  - 일정 기준: 라벨이 지정된 새 데이터는 매일, 매주, 매월
  - 새 학습 데이터: 새 데이터가 들어오는 경우 모델의 재학습을 트리거
  - 모델 성능 저하시: 성능저하가 눈에 띄는 경우
  - 데이터 분포의 중요한 변화 시 (concept drift): 예측을 수행하는 데 사용되는 피쳐의 데이터 분포에 큰 변화가 있으면, 모델이 오래된 것


### CI/CD 그리고 CT?
- continuous integration
- continuous deployment
- continuous training
  - 데이터 파이프라인  자동화
  - 기술부채들 해결


### MLOPS 의 성숙도 레벨
- 구글에서 정의하였음
  - MLOPS 성숙도 레벨 0
    - 수동 스크립트 중심, 대화식 interactive 프로세스
      - jupyter notebook 으로 만들어서 배포하는 것
    - ML과 운영의 분리
    - 드문 release 반복
      - 연간 1~2회
    - CI/CD 없음
    - 배포는 예측 서비스를 의미
    - Active 성능 모니터링 부족

![img src](https://user-images.githubusercontent.com/49462767/226177777-3b8e940a-b776-4a56-8e24-0fcdb46b9f1c.png)–


  - MLOPS 성숙도 레벨 1
    - 빠른 실험
    - 프로덕션 모델의 CT
    - 실험 운영 환경의 조화
    - 구성 요소 및 파이프라인을 위한 모듈화된 코드
    - 지속적인 모델 제공
    - 파이프라인 배포


![img src](https://user-images.githubusercontent.com/49462767/226177858-a2715097-e432-415d-bb33-531ab5edf497.png)


  - MLOPS 성숙도 레벨 2
    - production 에서 파이프라인을 빠르고 안정적으로 업데이트하는 '자동화' 된 CI/CD
    - CI/CD 시스템을 통해 데이터 사이언티스트들은 feature engineering, 모델 아키텍처 및 하이퍼 파라미터에 대한 아이디어를 신속하게 탐색 할 수 있음


![img src](https://user-images.githubusercontent.com/49462767/226177888-37c718d2-c261-484a-ab38-e0f8c465243a.png)






---
## REF
- https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning?hl=ko